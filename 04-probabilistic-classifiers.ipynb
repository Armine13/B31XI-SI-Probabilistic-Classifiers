{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Pattern recognition - ViBOT MsCV"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Guillaume Lemaitre - Fabrice Meriaudeau - Joan Massich"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "%matplotlib inline\n",
      "%pprint off\n",
      "\n",
      "# Matplotlib library\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "from matplotlib import cm\n",
      "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# MPLD3 extension\n",
      "import mpld3\n",
      "\n",
      "# Plotly library\n",
      "import plotly.plotly as py\n",
      "from plotly.graph_objs import *\n",
      "py.sign_in('glemaitre', 'se04g0bmi2')\n",
      "\n",
      "# Numpy library\n",
      "import numpy as np\n",
      "\n",
      "# To have some latex display\n",
      "from IPython.display import display, Math, Latex\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Pretty printing has been turned OFF\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Euclidean distance vs. Mahalanobis distance"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(a) Define the two distances anatycally."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(b) Comment in no more than three sentences on the differences between the two distances."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(c) Assume two 2-D Gaussian distributions defined by $\u03bc_1 = \\left( \\begin{array}{cc}\n",
      "1 & 1 \\end{array} \\right)^t$ and $\u03bc_2 = \\left( \\begin{array}{cc}\n",
      "4 & 4 \\end{array} \\right)^t$ with the following covariances:\n",
      "\n",
      "$\\Sigma_1 = \\left( \\begin{array}{cc}\n",
      "0.475 & -0.425 \\\\\n",
      "-0.425 & 0.475 \\end{array} \\right)$ and $\\Sigma_2 = \\left( \\begin{array}{cc}\n",
      "1 & 0 \\\\\n",
      "0 & 1 \\end{array} \\right)$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Define the mean and standard deviation for each distribution\n",
      "### Use np.matrix() to allow multiplication of matrices in the follow\n",
      "mu1 = ...\n",
      "sigma1 = ...\n",
      "mu2 = ...\n",
      "sigma2 = .\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Given a vector $x = \\left( \\begin{array}{cc}\n",
      "2 & 2 \\end{array} \\right)^t$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Define x\n",
      "### Use np.matrix() to allow multiplication of matrices in the follow\n",
      "x = ...\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(d) Complete the following function to compute the Euclidean distance given $x$. To which class $x$ will be affected using Euclidean distance?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Compute the Euclidean distance given x and the mean of a distribution\n",
      "### cf. check the function numpy.sqrt()\n",
      "### cf. check the function numpy.sum()\n",
      "### cf. check the function numpy.square()\n",
      "def EuclideanDistance(X, mu):\n",
      "    return ...\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Compute the distance between x and each class center\n",
      "d_c1 = ...\n",
      "d_c2 = ...\n",
      "\n",
      "if d_c1 < d_c2:\n",
      "    print 'The vector x will be affected to the class 1 with an Euclidean distance equal to {}'.format(d_c1)\n",
      "else:\n",
      "    print 'The vector x will be affected to the class 2 with an Euclidean distance equal to {}'.format(d_c2)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(e) Complete the following function to compute the Mahalanobis distance. To which class $x$ will be affected using Mahalanobis distance?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Define the Mahalanobis distance\n",
      "### cf. check the function numpy.transpose()\n",
      "### cf. check the function numpy.linalg.inv()\n",
      "def MahalanobisDistance(X, mean, cov):\n",
      "    return ..."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Compute the distance between x and each class center\n",
      "d_c1 = ...\n",
      "d_c2 = ...\n",
      "\n",
      "if d_c1 < d_c2:\n",
      "    print 'The vector x will be affected to the class 1 with an Mahalanobis distance equal to {}'.format(d_c1)\n",
      "else:\n",
      "    print 'The vector x will be affected to the class 2 with an Mahalanobis distance equal to {}'.format(d_c2)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(f) Generate 50 points from each distribution and plot them."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "### cf. check the function numpy.random.multivariate_normal()\n",
      "### cf. check the function np.asarray()\n",
      "### cf. check the function np.squeeze()\n",
      "\n",
      "# Generate the two distributions\n",
      "### Use the function np.random.multivariate_normal() and transpose\n",
      "x_d1, y_d1 = ...\n",
      "\n",
      "x_d2, y_d2 = ...\n",
      "\n",
      "# Plot the distributions\n",
      "...\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(g) Estimate the mean and covariance from the samples generated and compare with their theoritical values and comments briefly."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "### cf. check the function numpy.mean()\n",
      "### cf. check the function numpy.cov()\n",
      "\n",
      "# Estimation of the mean and std of the first class\n",
      "est_mean_d1 = ...\n",
      "est_cov_d1 = ...\n",
      "\n",
      "# Estimation of the mean and std of the second class\n",
      "est_mean_d2 = ...\n",
      "est_cov_d2 = ...\n",
      "\n",
      "print 'First class statistics: mean = {} and covariance = {}'.format(est_mean_d1, est_cov_d1)\n",
      "print 'Second class statistics: mean = {} and covariance = {}'.format(est_mean_d2, est_cov_d2)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(h) Now, generate 1000 points and retry the experiments of (d) and (e)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "### cf. check the function numpy.random.multivariate_normal()\n",
      "### cf. check the function np.asarray()\n",
      "### cf. check the function np.squeeze()\n",
      "\n",
      "# Generate the two distributions\n",
      "### Use the function np.random.multivariate_normal() and transpose\n",
      "x_d1, y_d1 = ...\n",
      "\n",
      "x_d2, y_d2 = ...\n",
      "\n",
      "### cf. check the function numpy.mean()\n",
      "### cf. check the function numpy.cov()\n",
      "\n",
      "# Estimation of the mean and std of the first class\n",
      "est_mean_d1 = ...\n",
      "est_cov_d1 = ...\n",
      "\n",
      "# Estimation of the mean and std of the second class\n",
      "est_mean_d2 = ...\n",
      "est_cov_d2 = ...\n",
      "\n",
      "print 'First class statistics: mean = {} and covariance = {}'.format(est_mean_d1, est_cov_d1)\n",
      "print 'Second class statistics: mean = {} and covariance = {}'.format(est_mean_d2, est_cov_d2)\n",
      "\n",
      "# Plot the distributions\n",
      "...\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(i) Define a function to compute the likelihood probability for a multivariate Gaussian density."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Define the function to compute the likelihood given the \n",
      "# distribution parameter\n",
      "def LikelihoodND(x, mean, cov):\n",
      "    return ...\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(j) Generate the PDFs for each of these densities and plot them as a surface."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Generate the meshgrid\n",
      "### cf. check the function numpy.linspace()\n",
      "### cf. check the function numpy.meshgrid()\n",
      "x = ...\n",
      "y = ...\n",
      "X, Y = np.meshgrid(...)\n",
      "\n",
      "# Generate the first PDF\n",
      "### cf. check the function numpy.zeros()\n",
      "Z_d1 = np.zeros(np.shape(X))\n",
      "...\n",
      "\n",
      "# Generate the second PDF\n",
      "### cf. check the function numpy.zeros()\n",
      "Z_d2 = np.zeros(np.shape(X))\n",
      "...\n",
      "\n",
      "# Plot the surface\n",
      "### cf. check matplotlib.plot_surface()\n",
      "### cf. check matplotlib.colorbar()\n",
      "\n",
      "data = Data([Surface(x=X, y=Y, z=Z_d1 + Z_d2, colorscale='Jet')])\n",
      "layout = Layout(margin=Margin(l=0, r=0, b=0, t=0))\n",
      "fig = Figure(data=data, layout=layout)\n",
      "py.iplot(fig, filename='densities-eucl-maha')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Logistic regression classifier"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this section, the data correspond to the grades of two examaminations of 80 students from which 40 students were admitted while the others failed."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Load the data\n",
      "data = np.asmatrix(np.loadtxt('./data/data.dat'))\n",
      "labels = np.asmatrix(np.transpose(np.atleast_2d(np.loadtxt('./data/labels.dat'))))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The grades are stored in the `data` variable whereas `labels` variable corresponds to the admission boolean."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(a) Plot the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Get the positive index\n",
      "pos_idx = ...\n",
      "\n",
      "# Get the negative index\n",
      "neg_idx = ...\n",
      "\n",
      "# Plot the data\n",
      "...\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We defined the sigmoid function as:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Definition of the sigmoid function\n",
      "def sigmoid(x):\n",
      "    return (1. / (1 + np.exp(-x)))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, the aim is to implement a logistic regression classifier. A logistic regression classifier return the probability such as:\n",
      "\n",
      "$$p(y | x; \\theta) = (h_{\\theta}(x))^{y} (1 - h_{\\theta}(x))^{1 - y} \\ ,$$\n",
      "\n",
      "with $h_{\\theta}(x) = \\frac{1}{1 + \\exp(- \\theta^{T} x)}$\n",
      "\n",
      "where $x$ is the feature vector (i.e., the observations), $\\theta$ is the set of parameters learned during the training stage.\n",
      "\n",
      "The set of parameters $\\theta$ can be found by maximizing the log likelihood which is defined as:\n",
      "\n",
      "$$l(\\theta) = \\sum_{i = 1}^{N} - y_i \\log h_{\\theta}(x_i) - (1 - y_i) \\log (1 - h_{\\theta}(x_i)) $$\n",
      "\n",
      "(b) Define the likelihood function in the following.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Define the likelihood\n",
      "def likelihood(x, h, y):\n",
      "    return ...\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The optimal parameters $\\theta$ can be found through numerical optimization by maximizing $l(\\theta)$. Herein, Newton's method will be used to optimize $l(\\theta)$.\n",
      "\n",
      "Newton's method is an iterative procedure in which the set of parameters $\\theta$ is updated such as:\n",
      "\n",
      "$$\\theta := \\theta - H^{-1} \\nabla_{\\theta}l(\\theta) \\ , $$\n",
      "\n",
      "(c) Complete the following function in order to follow the above definition."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Define the update rule of Newton's method\n",
      "def update_newton(theta_old, grad, H):\n",
      "    return ...\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We recall that the gradient of the likelihood $l(\\theta)$ is defined as:\n",
      "\n",
      "$$\\nabla_{\\theta}l(\\theta) = \\frac{1}{m} x^{T}(h_{\\theta}(x) - y) \\ ,$$\n",
      "\n",
      "(d) Complete the following Python function to cope with the previous definition. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Define the gradient of the likelihood\n",
      "def grad_likelihood(x, h, y):\n",
      "    return ...\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally the Hessian of the likelihood is defined as:\n",
      "\n",
      "$$H = \\frac{1}{m} x^{T} \\text{diag}(h_{\\theta}(x)) \\text{diag}(1 - h_{\\theta}(x)) x \\ .$$\n",
      "\n",
      "(e) Complete this Python function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Define the Hessian\n",
      "def hessian(x, h, y):\n",
      "    return ...\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(f) All the elements necessary to implement the Newton's optimisation have been defined. Complete the following code which will return the best set of parameters."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Implementation of the Newton's method\n",
      "def arg_max_likelihood(x, y, theta, max_iter = 15, epsilon = .00001):\n",
      "    \n",
      "    # Updating loops\n",
      "    it = 0\n",
      "    err = float(\"inf\")\n",
      "    while((it < max_iter)&(err > epsilon)):\n",
      "        # Store the theta values\n",
      "        theta_old = theta\n",
      "        \n",
      "        # Compute h(x)\n",
      "        h = ...\n",
      "        # Compute the current likelihood\n",
      "        l_theta = ...\n",
      "        # Compute the first derivative of the likelihood\n",
      "        grad = ...\n",
      "        # Compute the hessian matrix\n",
      "        H = ...\n",
      "        \n",
      "        # Update the set of parameters\n",
      "        theta = ...\n",
      "        \n",
      "        # Print some information\n",
      "        print 'Iteration #{0}: the cost function is equal to {1:.2f} and the parameters are {2}'.format(it, l_theta, np.ravel(theta.T))\n",
      "        \n",
      "        # Compute the convergence rate\n",
      "        err = np.sum(np.abs(theta - theta_old))\n",
      "        # Increment the number of iterations\n",
      "        it += 1\n",
      "        \n",
      "    # Return the set of parameter\n",
      "    return theta\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(g) Apply Newton's method to the given dataset to find the best set of parameters $\\theta$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Include the intercept in the data\n",
      "data_intercept = np.asmatrix(np.concatenate((np.ones((np.shape(data)[0], 1)), data), axis=1))\n",
      "\n",
      "# Create a matrix for the set of parameters\n",
      "theta = np.asmatrix(np.zeros((np.shape(data)[1] + 1, 1)))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Find the parameters which maximize the likelihood\n",
      "theta = arg_max_likelihood(...)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(h) What is the probability that a student with a score of 20 on exam #1 and a score of 80 on exam #2 will not be admitted. It can be formalized as:\n",
      "$$p(y = 0 | x) = 1 - p(y = 0 | x) \\text{ with } x = \\{20,80\\}$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Define the vector x \n",
      "x = np.matrix([[1., 20., 80.]])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Compute the probability\n",
      "print 'The probability is {}'.format(...)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(i) Find the boundary decision analatically. We recall that the boundary is defined such as:\n",
      "$$p(y = 1 | x) = p(y = 0 | x)$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We know that:\n",
      "$$p(y = 1 | x) = p(y = 0 | x)$$\n",
      "Thus,\n",
      "$$\\frac{1}{1 + \\exp( \\theta^{T} x)} = \\frac{\\exp( \\theta^{T} x)}{1 + \\exp( \\theta^{T} x)} \\ , $$\n",
      "\n",
      "$$\\exp( \\theta^{T} x) = 1 \\ , $$\n",
      "\n",
      "$$x_2 = -\\frac{(\\theta_1 x_1 + \\theta_0)}{\\theta_2} \\ .$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Get the positive index\n",
      "pos_idx = ...\n",
      "\n",
      "# Get the negative index\n",
      "neg_idx = ...\n",
      "\n",
      "# Plot the data\n",
      "...\n",
      "\n",
      "# Compute two points to draw a line\n",
      "x1, x2 = 20., 65.\n",
      "y1 = ...\n",
      "y2 = ...\n",
      "\n",
      "# Draw the line\n",
      "...\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As reference, we give an example of the same classifier already implemented in scikit-learn."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Import the right library\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "# Call the constructor\n",
      "lg_reg = LogisticRegression()\n",
      "lg_reg.fit(data, np.ravel(labels))\n",
      "\n",
      "# Compute the probability for x = {20., 80.}\n",
      "x = np.matrix([[20., 80.]])\n",
      "prob_y = lg_reg.predict_proba(x)\n",
      "\n",
      "# Print the results\n",
      "print 'The probability for x to be affected to class #0 is {}'.format(prob_y[0, 0])\n",
      "print 'The probability for x to be affected to class #1 is {}'.format(prob_y[0, 1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Bayesian classification for binary classification in a 1-D feature space"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In a 1-D feature space, the conditional density of the class #1 ($c_1$) is following a normal distribution (i.e., Gaussian distribution) with the following mean and variance $ \\mu_{1} = 0, \\ \\sigma_{1}^{2} = 5$. The class #2 ($c_2$) conditional density is also defined by a normal distribution with $ \\mu_{2} = 2, \\ \\sigma_{2}^{2} = 1$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(a) Give the mathematical representation of the two conditional densities."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "$p(X | c_1) = \\frac{1}{\\sqrt{2\\pi}\\sigma_{1}^{2}}\\exp{-\\frac{(x - \\mu_{1})^{2}}{2 \\sigma_{1}^{2}}}$\n",
      "\n",
      "$p(X | c_2) = \\frac{1}{\\sqrt{2\\pi}\\sigma_{2}^{2}}\\exp{-\\frac{(x - \\mu_{2})^{2}}{2 \\sigma_{2}^{2}}}$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(b) Complete the following Python function to return a Gaussian PDF for a given vector $X$, mean $\\mu$ and standard deviation $\\sigma$. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Create a function in order to generate a Gaussian function\n",
      "### cf. check the function numpy.sqrt()\n",
      "### cf. check the function numpy.exp()\n",
      "### cf. check the operator ** - power operator\n",
      "def Gaussian1D(X, mu, sigma):\n",
      "    return ...\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(c) Generate both $p(X | c_1)$ and $p(X | c_2)$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Define the mean and standard deviation for each distribution\n",
      "mu1, sigma1 = ...\n",
      "mu2, sigma2 = ...\n",
      "\n",
      "# Generate X\n",
      "### cf. check the function numpy.linspace()\n",
      "X = ...\n",
      "\n",
      "# Compute the different PDFs for both class\n",
      "pdf1 = ...\n",
      "pdf2 = ...\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(d) Plot the generated density functions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Plot the pdfs\n",
      "### cf. check the function matplotlib.plot()\n",
      "### cf. check the parameter label\n",
      "### cf. check the function matplotlib.legend()\n",
      "### cf. check the function matplotlib.show()\n",
      "...\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(e) Give the equation for the likelihood ratio and plot this ratio for a given vector $X$. Plot the decision constant    "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$\\Lambda(x) = \\frac{p(x|c_1)}{p(x|c_2)} = \\frac{1}{\\sqrt{5}} \\exp(0.4x^2 - 2x + 2)$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Generate X\n",
      "### cf. check the function numpy.linspace()\n",
      "X_ratio = ...\n",
      "\n",
      "# Generate the ratio from the analytical expression\n",
      "### cf. check the function numpy.sqrt()\n",
      "### cf. check the function numpy.exp()\n",
      "### cf. check the operator ** - power operator\n",
      "likelihood_ratio = ...\n",
      "\n",
      "# Plot the likelihood ratio\n",
      "### cf. check the function matplotlib.title()\n",
      "### Plot the likelihood ratio using the previous densities generated\n",
      "...\n",
      "### Plot the likelihood ratio using the analytical expression\n",
      "...\n",
      "### Plot the decision constant\n",
      "...\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(f) Complete the following Python function to return the likelihood probability given a scalar $x$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Function to return the likelihood probability\n",
      "def Likelihood1D(x, mu, sigma):\n",
      "    return ...\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(g) Complete the following Python function to return the posterior probability given a scalar $x$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Function to return the posterior probability\n",
      "def Posterior1D(x, mu, sigma, prior):\n",
      "    return ...\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(h) Assume the *a-priori* probabilities $P(c_1) = P(c_2) = 0.5$ and $x = 3$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Define the observation\n",
      "x = 3.\n",
      "\n",
      "# Define the prior probability\n",
      "p_c1, p_c2 = .5, .5\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Using the Maximum Likelihood (ML) approach, which class will be affected to $x$?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Compute the likelihood for the two classes\n",
      "p_x_c1 = ...\n",
      "p_x_c2 = ...\n",
      "\n",
      "display(Math('p(x = 3 | c_1)'), p_x_c1)\n",
      "display(Math('p(x = 3 | c_2)'), p_x_c2)\n",
      "\n",
      "# In the ML sense, check which class to affect x\n",
      "...\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Using the Maximum *a-posteriori* (MAP) approach, which class will be affected to $x$?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Compute the likelihood for the two classes\n",
      "p_c1_x = ...\n",
      "p_c2_x = ...\n",
      "\n",
      "display(Math('p(c_1 | x = 3)'), p_c1_x)\n",
      "display(Math('p(c_2 | x = 3)'), p_c2_x)\n",
      "\n",
      "# In the ML sense, check which class to affect x\n",
      "...\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- How many decision regions do you observe? Describe those regions based on your sketch."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Plot the previous pdf - refer question (d)\n",
      "...\n",
      "\n",
      "# Plot the different region of decision\n",
      "### cf. check the function matplotlib.fill_between()\n",
      "...\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Three regions observable"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Write the integral equation that gives the overall probability of error based on the MAP method."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Compute the classification error\n",
      "p_error = ...\n",
      "\n",
      "display(Math('p(\\epsilon)'), p_error)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Find the decision boundary (or boundaries) using analytical methods (not the sketch)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(i) Now, assume the *a-priori* probabilities $P(c_1) = 0.8$ and $P(c_2) = 0.2$, $x = 3$ and a zero-one loss function:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Define the observation\n",
      "x = 3.\n",
      "\n",
      "# Define the prior probability\n",
      "p_c1, p_c2 = .8, .2\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Sketch the product of the conditional density and its corresponding prior for both classes $c_1$ and $c_2$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Compute the product of the previous densities with their priors\n",
      "...\n",
      "\n",
      "# Normalise the densities\n",
      "...\n",
      "\n",
      "# Plot the previous pdf\n",
      "...\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Using the Maximum Likelihood (ML) approach, which class will be affected to an observation such as $x = 3$?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Compute the likelihood for the two classes\n",
      "...\n",
      "\n",
      "display(Math('p(x = 3 | c_1)'), p_x_c1)\n",
      "display(Math('p(x = 3 | c_2)'), p_x_c2)\n",
      "\n",
      "# In the ML sense, check which class to affect x\n",
      "...\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Using the Maximum *a-posteriori* (MAP) approach, which class will be affected to $x$?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Compute the likelihood for the two classes\n",
      "...\n",
      "\n",
      "display(Math('p(c_1 | x = 3)'), p_c1_x)\n",
      "display(Math('p(c_2 | x = 3)'), p_c2_x)\n",
      "\n",
      "# In the ML sense, check which class to affect x\n",
      "...\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- How many decision regions do you observe? Describe those regions based on your sketch."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Plot the previous pdf - refer question (d)\n",
      "...\n",
      "# Plot the different region of decision\n",
      "### cf. check the function matplotlib.fill_between()\n",
      "...\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Only one region observable"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Write the integral equation that gives the overall probability of error based on the MAP method."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Compute the classification error\n",
      "p_error = ...\n",
      "\n",
      "display(Math('p(\\epsilon)'), p_error)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Find the decision boundary (or boundaries) using analytical methods (not the sketch)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- What kind of loss values (rather than zero-one) would alter the decisions?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Naive Bayes classifier applied for segmentation in retina images"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Import scikit-image for input-output manipulation\n",
      "from skimage import io\n",
      "from skimage import img_as_float\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(a) From the `data` folder load the training image `training.tif`, the vessel image `training_vessels.gif` and the mask FOV `training_mask.gif`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Load the images\n",
      "### Use the function img_as_float()\n",
      "### Use the function io.imread()\n",
      "train_im = ...\n",
      "train_ve = ...\n",
      "train_ma = ...\n",
      "\n",
      "# Render the image\n",
      "fig, ax = plt.subplots(1, 3)\n",
      "ax1, ax2, ax3 = ax.ravel()\n",
      "\n",
      "ax1.imshow(train_im)\n",
      "ax1.set_title('Original image')\n",
      "ax1.axis('off')\n",
      "\n",
      "ax2.imshow(train_ve, cmap=plt.cm.gray)\n",
      "ax2.set_title('Vessel mask')\n",
      "ax2.axis('off')\n",
      "\n",
      "ax3.imshow(train_ma, cmap=plt.cm.gray)\n",
      "ax3.set_title('Fovea mask')\n",
      "ax3.axis('off')\n",
      "\n",
      "plt.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Import the scikit-image for color conversion\n",
      "from skimage import color\n",
      "# Import morpho element\n",
      "from skimage.morphology import square\n",
      "# Import the median filtering\n",
      "from skimage.filter.rank import median\n",
      "\n",
      "# Function to pre process the images\n",
      "def PreProcessing(rgb_image):\n",
      "    # Convert RGB to LAB color space\n",
      "    lab_image = img_as_float(color.rgb2lab(rgb_image))\n",
      "    \n",
      "    # Normalize each channel between 0 and 1\n",
      "    lab_image[:, :, 0] = normalise_im(lab_image[:, :, 0])\n",
      "    lab_image[:, :, 1] = normalise_im(lab_image[:, :, 1])\n",
      "    lab_image[:, :, 2] = normalise_im(lab_image[:, :, 2])\n",
      "    \n",
      "    # Obtain a background image through median filtering\n",
      "    background_im = img_as_float(median(lab_image[:, :, 0], square(15)))\n",
      "    tmp_im = lab_image[:, :, 0] - background_im\n",
      "    tmp_im[tmp_im > 0] = 0\n",
      "    lab_image[:, :, 0] = - tmp_im\n",
      "    lab_image[:, :, 0] = normalise_im(lab_image[:, :, 0])\n",
      "    \n",
      "    return lab_image\n",
      "\n",
      "def normalise_im(im_2d):\n",
      "    return (im_2d[:, :] - np.min(im_2d[:, :])) / (np.max(im_2d[:, :]) - np.min(im_2d[:, :]))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Pre-process the training image and render it\n",
      "pre_proc_im = PreProcessing(train_im)\n",
      "fig, ax = plt.subplots(1, 3)\n",
      "ax1, ax2, ax3 = ax.ravel()\n",
      "\n",
      "ax1.imshow(pre_proc_im[:, :, 0], cmap=plt.cm.gray)\n",
      "ax1.set_title('Vessel')\n",
      "ax1.axis('off')\n",
      "\n",
      "ax2.imshow(pre_proc_im[:, :, 1], cmap=plt.cm.gray)\n",
      "ax2.set_title('Channel A')\n",
      "ax2.axis('off')\n",
      "\n",
      "ax3.imshow(pre_proc_im[:, :, 2], cmap=plt.cm.gray)\n",
      "ax3.set_title('Channel B')\n",
      "ax3.axis('off')\n",
      "\n",
      "plt.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(b) Create the positive and negative samples from the 3 colour spaces and with the vessel image and the mask image. Your feature space will be three dimensional. Remember that each pixel is a sample with 3 features, with a positive class if it lays to the vessels and negative otherwise."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Create the positive samples\n",
      "idx_pos_y, idx_pos_x = ...\n",
      "pos_fea = ...\n",
      "\n",
      "# Create the negative samples\n",
      "idx_neg_y, idx_neg_x = ...\n",
      "neg_fea = ...\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(c) Plot the 1-D histogram of each feature seperately and evaluate the separability of the classes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Define the number of bin\n",
      "nb_bins = 50\n",
      "\n",
      "### 1st feature ###\n",
      "plt.figure()\n",
      "# For the positive sample\n",
      "n, bins, patches = plt.hist(...)\n",
      "plt.setp(...)\n",
      "# For the neg sample\n",
      "n, bins, patches = plt.hist(...)\n",
      "plt.setp(...)\n",
      "plt.title('1st feature PDF')\n",
      "\n",
      "### 2nd feature ###\n",
      "plt.figure()\n",
      "# For the positive sample\n",
      "n, bins, patches = plt.hist(...)\n",
      "plt.setp(...)\n",
      "# For the neg sample\n",
      "n, bins, patches = plt.hist(...)\n",
      "plt.setp(...)\n",
      "plt.title('2nd feature PDF')\n",
      "\n",
      "### 3rd feature ###\n",
      "plt.figure()\n",
      "# For the positive sample\n",
      "n, bins, patches = plt.hist(...)\n",
      "plt.setp(...)\n",
      "# For the neg sample\n",
      "n, bins, patches = plt.hist(...)\n",
      "plt.setp(...)\n",
      "plt.title('3rd feature PDF')\n",
      "\n",
      "plt.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(d) Assuming a normal distribution of the samples train a Naive Bayes classifier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Define the prior of each class\n",
      "prior_pos, prior_neg = .5, .5\n",
      "\n",
      "# Estimation of the mean and std of the first class\n",
      "est_mean_pos = ...\n",
      "est_cov_pos = ...\n",
      "\n",
      "# Estimation of the mean and std of the second class\n",
      "est_mean_neg = ...\n",
      "est_cov_neg = ...\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(e) Load the test image `test.tif` and use the previous model learned to segment the image."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Function to return the posterior probability for N-D\n",
      "def PosteriorND(x, mu, sigma, prior):\n",
      "    return LikelihoodND(x, mu, sigma) * prior\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Load the image\n",
      "test_im = ...\n",
      "test_ma = ...\n",
      "\n",
      "# Pre-process the image\n",
      "pre_proc_im_test = PreProcessing(test_im)\n",
      "\n",
      "# Build the feature vector\n",
      "idx_test_y, idx_test_x = ...\n",
      "test_fea = ...\n",
      "\n",
      "# Pre allocation\n",
      "seg_im = np.zeros(np.shape(test_ma))\n",
      "# Classify each sample\n",
      "for f in range(0, np.size(test_fea, 0)):\n",
      "    # Estimate the probability for the positive class\n",
      "    p_pos_x = ...\n",
      "    # Estimate the probability for the negative class\n",
      "    p_neg_x = ...\n",
      "    # Decide depending on the ratio\n",
      "    if ((p_pos_x / p_neg_x) > 1.0):\n",
      "        seg_im[idx_test_y[f]][idx_test_x[f]] = 1.0\n",
      "            \n",
      "# Show the results\n",
      "fig, ax = plt.subplots()\n",
      "ax.imshow(seg_im, cmap=plt.cm.gray)\n",
      "ax.axis('off')\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}